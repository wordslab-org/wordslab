https://powersj.io/posts/ubuntu-qemu-cli/

Ubuntu creates cloud images for use with a wide variety of platforms.

These local images are published at https://cloud-images.ubuntu.com.

Images are published daily when any package in the images change. In practice, this means a new image may not be available every day. 
A release image is published when one of a specific set of packages that are critical to the image is updated, like the kernel, grub, or cloud-init. Additionally, if a security update occurs that is critical a release image may get published.

Daily images : https://cloud-images.ubuntu.com/daily/server/
Release images : https://cloud-images.ubuntu.com/releases/

Most of the images found on the cloud-images.ubuntu.com are the standard server image. 
However, there are also a set of minimal Ubuntu images, which have a reduced package for a smaller image and reduced attack surface. These images also come with a custom kernel for even faster operations.

Minimal images : https://cloud-images.ubuntu.com/minimal/

QEMU users will want to download the .img file, which is a QEMU QCOW2 image. 

> https://cloud-images.ubuntu.com/minimal/releases/focal/release-20220201/ubuntu-20.04-minimal-cloudimg-amd64.img

When instances are launched in a cloud deployment cloud-init will search for a datasource to retrieve instance metadata. 
This data is used to determine what users to create, set a hostname, networking configuration, and many other possible configuration settings.

https://cloudinit.readthedocs.io/en/latest/

Cloud-init is the industry standard multi-distribution method for cross-platform cloud instance initialization. 
It is supported across all major public cloud providers, provisioning systems for private cloud infrastructure, and bare-metal installations.

Cloud images will take in two types of data:
- metadata: unique configuration data provided by the cloud platform. The values of this data vary depending on the cloud provider. It can include a hostname, networking information, SSH keys, etc.
- user data: provided directly by the user to configure the system. This data is simple as a shell script to execute or include cloud-config data that the user can specify settings in a human-friendly format.

In the case of launching a local QEMU image, the user needs to provide a local datasource for the cloud image to read from. 
From this datasource, the instance can read both the metadata and/or user data to configure the system.

To provide the local datasource, users create a seed image containing the metadata, user data, and even networking information. 
The cloud-localds command from the cloud-image-utils package is used to generate the seed image.

1. First, create a metadata file with the desired instance ID and hostname:

$ cat > metadata.yaml <<EOF
instance-id: iid-wordslab
local-hostname: wordslab
EOF

2. Next, create a user data file to provide the SSH key to the instance. 

The example below uses cloud-init’s cloud-config to pass this information to automatically add the key to the default user. 
There are two cloud-config keys that can import an SSH key:
- ssh_import_id: provide a list of public SSH keys to import from GitHub or Launchpad
- ssh_authorized_keys: provide the raw SSH public key text to add directly to the authorized keys file

Users can use both options, but only one is needed:

$ cat > user-data.yaml <<EOF
#cloud-config
ssh_authorized_keys:
  - ssh-rsa AAAAB3NzaC1yc2EAAAABIwJJJQEA3I7VUf3l5gSn5uavROsc5HRDpZ ...
ssh_import_id:
  - gh:<github user>
  - lp:<launchpad user>
EOF

Note that #cloud-config is required to be on the first line. 

For the full list of cloud-config options checkout the cloud-init docs.

https://cloudinit.readthedocs.io/en/latest/topics/examples.html#yaml-examples

3. Install the cloud-image-utils package

$ sudo apt-get update -y
$ sudo apt-get install -y cloud-image-utils

4. Finally, generate the seed image that combines the metadata and user data files:

$ cloud-localds seed.img user-data.yaml metadata.yaml

5. Booting with SeaBIOS 

The default firmware with QEMU is to boot with SeaBIOS, an open-source BIOS implementation.

Here is an example command:

$ qemu-system-x86_64  \
  -machine accel=kvm,type=q35 \
  -cpu host \
  -m 2G \
  -nographic \
  -device virtio-net-pci,netdev=net0 \
  -netdev user,id=net0,hostfwd=tcp::2222-:22 \
  -drive if=virtio,format=qcow2,file=focal-server-cloudimg-amd64.img \
  -drive if=virtio,format=raw,file=seed.img

- machine accel=kvm,type=q35 : enables kernel-based virtual machine (KVM) acceleration, sets the machine type to use the Q35 chipset which has a PCIe root complex with more modern capabilities
- cpu host : pass all available host processor features to the guest. This option can be supplemented with the -smp option to specify a particular number of processors as well as topology via the number of sockets, cores, or threads
- m 2G : set the amount of memory for an instance
- nographic : disables the graphical output and makes the command treat the QEMU command as a CLI application. Type <Ctrl-a> x to quit the process.
- device virtio-net-pci,netdev=net0 : creates a virtio pass-through network device
- netdev user,id=net0,hostfwd=tcp::2222-:22 : tells QEMU to listen on port 2222 and connections to that port will be relayed to the VM on port 22. This way users can SSH to the VM without knowing the IP address of the system via ssh -p 2222 localhost
- drive if=virtio,format=qcow2,file=ubuntu-20.04-server-cloudimg-amd64.img : adds a virtio drive using the Ubuntu qcow2 image downloaded earlier
- drive if=virtio,format=raw,file=seed.img : adds another virtio drive for the created seed image that will act as the local datasource

Because the above QEMU command uses the -nographic option, the serial console output will go to the terminal the user is using. 
To interact with the underlying QEMU process the <Ctrl-a> key combination is used to send QEMU commands.

For example, to terminate the QEMU process the user can run <Ctrl-a> x rather than shutting down the VM via the CLI.
Additionally, users can access the QEMU monitor by running <Ctrl-a> c where they can run additional QEMU commands. 
Once run the prompt will change to (qemu) and users can run commands like sendkeys to send the VM key combinations, type quit to quit, or type help for even more options.

6. Login with SSH 

With the above options set, users can access the VM directly via the serial console or in other terminal SSH to the VM. 
If the user’s SSH key was imported successfully, the user can then SSH to the VM using port 2222:

ssh -o "StrictHostKeyChecking no" -p 2222 ubuntu@0.0.0.0

When using this option a lot, it is helpful to add the -o "StrictHostKeyChecking no" option to the SSH command to not get prompted about changing SSH host keys for every different image.

7. Helpful QEMU CLI Options

-snapshot writes to a temporary file instead of the disk image itself. This ensures the base disk is not modified and is great if a user only wants to verify a file in the image or test a boot while keeping the image pristine.

-o backing_file= similar to snapshot, using a backing file will let the user keep the original image pristine, but write changes to a second file. See the QEMU Snapshot wiki page for an example.

-D logfile output log in logfile instead of to stderr


NOTES ON LINUX GPU PARAVIRTUALIZATION

https://wiki.archlinux.org/title/QEMU/Guest_graphics_acceleration

Virgil3d virtio-gpu is a paravirtualized 3d accelerated graphics driver, similar to non-graphics virtio drivers (see virtio driver information and virtio Windows guest drivers). 
Virgil3d : 
https://virgil3d.github.io/

Virgil is a research project to investigate the possibility of creating a virtual 3D GPU for use inside qemu virtual machines, that allows the guest operating system to use the capabilities of the host GPU to accelerate 3D rendering. 
The plan is to have a guest GPU that is fully independent of the host GPU.

The project entails creating a virtual 3D capable graphics card for virtual machines running inside qemu. 
The design of this card is based around the concepts of Gallium3D to make writing Mesa and (eventually) Direct3D drivers for it easy. 
The card natively uses the Gallium TGSI intermediate representation for its shaders. 
The implementation of rendering for the card is done in the host system as part of qemu and is implemented purely on OpenGL so you can accelerated rendering on any sufficiently capable card/driver combination.

The project also consists of a complete Linux guest stack, composed of a Linux kernel KMS driver, X.org 2D DDX driver and Mesa 3D driver.

Non-graphics virtio drivers : 
https://wiki.archlinux.org/title/QEMU#Installing_virtio_drivers

Virtio driver information :
https://www.linux-kvm.org/page/Virtio

For Linux guests, virtio-gpu is fairly mature, having been available since Linux kernel version 4.4 and QEMU version 2.6. 
https://wiki.archlinux.org/title/QEMU#virtio

virtio-vga / virtio-gpu is a paravirtual 3D graphics driver based on virgl. 
Currently a work in progress, supporting only very recent (>= 4.4) Linux guests with mesa (>=11.2) compiled with the option gallium-drivers=virgl.
To enable 3D acceleration on the guest system select this vga with -device virtio-vga-gl and enable the opengl context in the display device with -display sdl,gl=on or -display gtk,gl=on for the sdl and gtk display output respectively. 
Successful configuration can be confirmed looking at the kernel log in the guest:
# dmesg | grep drm 
[drm] pci: virtio-vga detected
[drm] virgl 3d acceleration enabled

See this Reddit Arch thread and Gerd Hoffmann's blog for using this with libvirt and spice.
https://www.reddit.com/r/archlinux/comments/7nmceg/kvmqemu_with_virtiogpu_virgl_support_enabled/
https://www.kraxel.org/blog/2016/09/using-virtio-gpu-with-libvirt-and-spice/

Redhat - Managing NVIDIA vGPU devices
https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_virtualization/assembly_managing-gpu-devices-in-virtual-machines_configuring-and-managing-virtualization

The vGPU feature makes it possible to divide a physical NVIDIA GPU device into multiple virtual devices, referred to as mediated devices. 
These mediated devices can then be assigned to multiple virtual machines (VMs) as virtual GPUs.
As a result, these VMs can share the performance of a single physical GPU.

IMPORTANT
Assigning a physical GPU to VMs, with or without using mediated devices, makes it impossible for the host to use the GPU.

For an up-to-date list of NVIDIA GPUs that support creating vGPUs, see the NVIDIA GPU Software Documentation.
https://docs.nvidia.com/grid/latest/grid-vgpu-release-notes-red-hat-el-kvm/index.html#validated-platforms
=> Tesla, Quadro, A100, RTX A600 ...